{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bird Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "from sqlalchemy import create_engine, Table, Column, String, MetaData, Date, Integer, Boolean\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_key = os.environ.get('EBIRD_API_KEY')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET Requests to eBird API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetches species codes for all recorded observations in PA\n",
    "pa_species_url = 'https://api.ebird.org/v2/product/spplist/US-PA'\n",
    "pa_species_params = {'key': os.environ.get('EBIRD_API_KEY')}\n",
    "pa_species = requests.get(pa_species_url, params=pa_species_params)\n",
    "\n",
    "# Handle potential JSONDecodeError\n",
    "try:\n",
    "    pa_species_data = pa_species.json()\n",
    "except requests.exceptions.JSONDecodeError:\n",
    "    print(\"Error decoding JSON response for pa_species:\")\n",
    "    print(pa_species.text)\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetches all recent recorded observations in PA\n",
    "recent_observations_url = 'https://api.ebird.org/v2/data/obs/US-PA/recent'\n",
    "recent_observations_params = {'key': os.environ.get('EBIRD_API_KEY')}\n",
    "recent_observations = requests.get(recent_observations_url, params=recent_observations_params)\n",
    "\n",
    "# Handle potential JSONDecodeError\n",
    "try:\n",
    "    recent_observations_data = recent_observations.json()\n",
    "except requests.exceptions.JSONDecodeError:\n",
    "    print(\"Error decoding JSON response for recent_observations:\")\n",
    "    print(recent_observations.text)\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetches PA birding hotspots (in JSON format)\n",
    "pa_hotspots_url = 'https://api.ebird.org/v2/ref/hotspot/US-PA?fmt=json'\n",
    "pa_hotspots_params = {'key': os.environ.get('EBIRD_API_KEY')}\n",
    "pa_hotspots = requests.get(pa_hotspots_url, params=pa_hotspots_params)\n",
    "\n",
    "# Handle potential JSONDecodeError\n",
    "try:\n",
    "    pa_hotspots_data = pa_hotspots.json()\n",
    "except requests.exceptions.JSONDecodeError:\n",
    "    print(\"Error decoding JSON response for pa_hotspots:\")\n",
    "    print(pa_hotspots.text)\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fetches details about particular hotspot\n",
    "# hotspot_info_url = 'https://api.ebird.org/v2/ref/hotspot/info/{locId}'\n",
    "# hotspot_info_params = {'key': os.environ.get('EBIRD_API_KEY')}\n",
    "# hotspot_info = requests.get(hotspot_info_url, params=hotspot_info_params)\n",
    "\n",
    "# # Handle potential JSONDecodeError\n",
    "# try:\n",
    "#     hotspot_info_data = hotspot_info.json()\n",
    "# except requests.exceptions.JSONDecodeError:\n",
    "#     print(\"Error decoding JSON response for hotspot_info:\")\n",
    "#     print(hotspot_info.text)\n",
    "#     exit(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to hold API species response data\n",
    "pa_species_df = pd.DataFrame(pa_species_data)\n",
    "\n",
    "# Create a DataFrame to hold API observation response data\n",
    "pa_observations_df = pd.DataFrame(recent_observations_data)\n",
    "\n",
    "# Create a DataFrame to hold API response data for list of PA hotspots\n",
    "pa_hotspots_df = pd.DataFrame(pa_hotspots_data)\n",
    "\n",
    "# # Create a DataFrame to hold API response for hotspot location info\n",
    "# hotspot_info_df = pd.DataFrame(hotspot_info_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Returned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unneeded columns from observation data\n",
    "\n",
    "# Specify the columns to be dropped\n",
    "columns_to_drop = ['obsValid', 'obsReviewed', 'subId', 'exoticCategory']\n",
    "\n",
    "# Drop the specified columns from the DataFrame\n",
    "pa_observations_df = pa_observations_df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unneeded columns from the hotspot data\n",
    "\n",
    "# Specify the columns to be dropped\n",
    "columns_to_drop = ['countryCode', 'subnational1Code']\n",
    "\n",
    "# Drop the specified columns from the DataFrame\n",
    "pa_hotspots_df = pa_hotspots_df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for clarity in observation data\n",
    "pa_observations_df = pa_observations_df.rename(columns={'speciesCode': 'Species_Code', 'comName': 'Common_Name', 'sciName': 'Scientific_Name', \n",
    "                                                        'locId': 'Location_ID', 'locName': 'Location_Name', 'obsDt' : 'Observation_Date', \n",
    "                                                        'howMany': 'Quantity_Observed', 'lat': 'Latitude', 'lng': 'Longitude', \n",
    "                                                        'locationPrivate': 'Location_Private'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for clarity in hotspot data\n",
    "pa_hotspots_df = pa_hotspots_df.rename(columns={'locId': 'Location_ID', 'locName': 'Location_Name', 'subnational2Code': 'Sub-National_Code',\n",
    "                                                 'lat': 'Latitude', 'lng': 'Longitude', 'latestObsDt': 'Date_of_Most_Recent_Observation', \n",
    "                                                 'numSpeciesAllTime': 'Total_Species_Recorded_at_Location'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_species_df = pa_species_df.rename(columns={0: 'Species_Code'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write cleaned data to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write PA species list response data to a CSV file\n",
    "pa_species_df.to_csv('pa_species.csv', index=False)\n",
    "\n",
    "# Write recent observations response to a CSV file\n",
    "pa_observations_df.to_csv('recent_observations.csv', index=False)\n",
    "\n",
    "# Write PA hotspot response to a CSV file\n",
    "pa_hotspots_df.to_csv('pa_hotspots_data.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write observation data from CSV file to PostgreSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PostgreSQL database connection details from .env file\n",
    "# host = os.getenv('PG_HOST')\n",
    "# database = os.getenv('PG_DATABASE')\n",
    "# user = os.getenv('PG_USER')\n",
    "# password = os.getenv('PG_PASSWORD')\n",
    "\n",
    "# # CSV file path\n",
    "# csv_file = 'recent_observations.csv'\n",
    "\n",
    "# # Create SQLAlchemy engine\n",
    "# engine = create_engine(f'postgresql://{user}:{password}@{host}/{database}', pool_pre_ping=True)\n",
    "\n",
    "# # Create a session factory\n",
    "# Session = sessionmaker(bind=engine)\n",
    "# session = Session()\n",
    "\n",
    "# # Create SQLAlchemy table object\n",
    "# metadata = MetaData()\n",
    "# table = Table('Recent_Observations', metadata,\n",
    "#               Column('Index', primary_key=True, autoincrement=True),\n",
    "#               Column('Species_Code', String),\n",
    "#               Column('Common_Name', String),\n",
    "#               Column('Scientific_Name', String),\n",
    "#               Column('Location_ID', String),\n",
    "#               Column('Location_Name', String),\n",
    "#               Column('Observation_Date', Date),\n",
    "#               Column('Quantity_Observed', Integer),\n",
    "#               Column('Latitude', String),\n",
    "#               Column('Longitude', String),\n",
    "#               Column('Location_Private', Boolean)\n",
    "#               )\n",
    "\n",
    "# # Open the CSV file\n",
    "# with open(csv_file, 'r') as file:\n",
    "#     # Create a CSV reader object\n",
    "#     csv_data = csv.reader(file)\n",
    "\n",
    "#     # Skip the header row\n",
    "#     next(csv_data)\n",
    "\n",
    "#     # Insert each row of the CSV file into the database table\n",
    "#     for row in csv_data:\n",
    "#         insert_stmt = table.insert().values(Index=row[0], Species_Code=row[1], Common_Name=row[2], Scientific_Name=row[3],\n",
    "#                                             Location_ID=row[4], Location_Name=row[5], Observation_Date=row[6], Quantity_Observed=row[7], \n",
    "#                                             Latitude=row[8], Longitude=row[9], Location_Private=row[10])\n",
    "#         session.execute(insert_stmt)\n",
    "\n",
    "# # Commit the changes to the database\n",
    "# session.commit()\n",
    "\n",
    "# # Close the session\n",
    "# session.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 251 entries, 0 to 250\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Species_Code       251 non-null    object \n",
      " 1   Common_Name        251 non-null    object \n",
      " 2   Scientific_Name    251 non-null    object \n",
      " 3   Location_ID        251 non-null    object \n",
      " 4   Location_Name      251 non-null    object \n",
      " 5   Observation_Date   251 non-null    object \n",
      " 6   Quantity_Observed  248 non-null    float64\n",
      " 7   Latitude           251 non-null    float64\n",
      " 8   Longitude          251 non-null    float64\n",
      " 9   Location_Private   251 non-null    bool   \n",
      "dtypes: bool(1), float64(3), object(6)\n",
      "memory usage: 18.0+ KB\n"
     ]
    }
   ],
   "source": [
    "pa_observations_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_observations_df[(pa_observations_df.Common_Name == 'Pileated Woodpecker')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
