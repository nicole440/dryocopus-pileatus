{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bird Observation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and configure environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from sqlalchemy import create_engine, Table, Column, String, MetaData, Date, Integer, Boolean\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_key = os.environ.get('EBIRD_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET Requests to eBird API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetches all recent recorded observations in PA\n",
    "recent_observations_url = 'https://api.ebird.org/v2/data/obs/US-PA/recent'\n",
    "recent_observations_params = {'key': os.environ.get('EBIRD_API_KEY')}\n",
    "recent_observations = requests.get(recent_observations_url, params=recent_observations_params)\n",
    "\n",
    "# Handle potential JSONDecodeError\n",
    "try:\n",
    "    recent_observations_data = recent_observations.json()\n",
    "except requests.exceptions.JSONDecodeError:\n",
    "    print(\"Error decoding JSON response for recent_observations:\")\n",
    "    print(recent_observations.text)\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetches PA birding hotspots (in JSON format)\n",
    "pa_hotspots_url = 'https://api.ebird.org/v2/ref/hotspot/US-PA?fmt=json'\n",
    "pa_hotspots_params = {'key': os.environ.get('EBIRD_API_KEY')}\n",
    "pa_hotspots = requests.get(pa_hotspots_url, params=pa_hotspots_params)\n",
    "\n",
    "# Handle potential JSONDecodeError\n",
    "try:\n",
    "    pa_hotspots_data = pa_hotspots.json()\n",
    "except requests.exceptions.JSONDecodeError:\n",
    "    print(\"Error decoding JSON response for pa_hotspots:\")\n",
    "    print(pa_hotspots.text)\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fetches details about particular hotspot\n",
    "# # This won't work until I have a location ID\n",
    "# hotspot_info_url = 'https://api.ebird.org/v2/ref/hotspot/info/{locId}'\n",
    "# hotspot_info_params = {'key': os.environ.get('EBIRD_API_KEY')}\n",
    "# hotspot_info = requests.get(hotspot_info_url, params=hotspot_info_params)\n",
    "\n",
    "# # Handle potential JSONDecodeError\n",
    "# try:\n",
    "#     hotspot_info_data = hotspot_info.json()\n",
    "# except requests.exceptions.JSONDecodeError:\n",
    "#     print(\"Error decoding JSON response for hotspot_info:\")\n",
    "#     print(hotspot_info.text)\n",
    "#     exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to hold API observation response data\n",
    "pa_observations_df = pd.DataFrame(recent_observations_data)\n",
    "\n",
    "# Create a DataFrame to hold API response data for list of PA hotspots\n",
    "pa_hotspots_df = pd.DataFrame(pa_hotspots_data)\n",
    "\n",
    "# # Create a DataFrame to hold API response for hotspot location info\n",
    "# hotspot_info_df = pd.DataFrame(hotspot_info_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Returned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unneeded columns from observation data\n",
    "\n",
    "# Specify the columns to be dropped\n",
    "columns_to_drop = ['obsValid', 'obsReviewed', 'subId', 'exoticCategory']\n",
    "\n",
    "# Drop the specified columns from the DataFrame\n",
    "pa_observations_df = pa_observations_df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unneeded columns from the hotspot data\n",
    "\n",
    "# Specify the columns to be dropped\n",
    "columns_to_drop = ['countryCode', 'subnational1Code']\n",
    "\n",
    "# Drop the specified columns from the DataFrame\n",
    "pa_hotspots_df = pa_hotspots_df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for clarity in observation data\n",
    "pa_observations_df = pa_observations_df.rename(columns={'speciesCode': 'Species_Code', 'comName': 'Common_Name', 'sciName': 'Scientific_Name', \n",
    "                                                        'locId': 'Location_ID', 'locName': 'Location_Name', 'obsDt' : 'Observation_Date', \n",
    "                                                        'howMany': 'Quantity_Observed', 'lat': 'Latitude', 'lng': 'Longitude', \n",
    "                                                        'locationPrivate': 'Location_Private'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pa_observations_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for clarity in hotspot data\n",
    "pa_hotspots_df = pa_hotspots_df.rename(columns={'locId': 'Location_ID', 'locName': 'Location_Name', 'subnational2Code': 'Sub-National_Code',\n",
    "                                                 'lat': 'Latitude', 'lng': 'Longitude', 'latestObsDt': 'Date_of_Most_Recent_Observation', \n",
    "                                                 'numSpeciesAllTime': 'Total_Species_Recorded_at_Location'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write cleaned data to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write recent observations response to a CSV file\n",
    "pa_observations_df.to_csv('recent_observations.csv', index=True)\n",
    "\n",
    "# Write PA hotspot response to a CSV file\n",
    "pa_hotspots_df.to_csv('pa_hotspots_data.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write observation data from Pandas DataFrame to SQLite database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create SQLite Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Specify column names\n",
    "column_names = ['Species_Code', 'Common_Name', 'Scientific_Name', 'Location_ID', 'Location_Name',\n",
    "                'Observation_Date', 'Quantity_Observed', 'Latitude', 'Longitude', 'Location_Private']\n",
    "\n",
    "connection = sqlite3.connect(\"observation-data.db\")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "cursor.execute(\"DROP TABLE IF EXISTS Observations;\")\n",
    "\n",
    "# Create the table with the appropriate columns\n",
    "create_table_query = \"CREATE TABLE Observations ({})\".format(\", \".join(column_names))\n",
    "cursor.execute(create_table_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write data to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert values from the DataFrame into the table\n",
    "\n",
    "for i in range(len(pa_observations_df)):\n",
    "    cursor.execute(\"INSERT INTO Observations VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\", pa_observations_df.iloc[i])\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write observation data from CSV file to PostgreSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sqlalchemy import Integer\n",
    "\n",
    "# # PostgreSQL database connection details from .env file\n",
    "# host = os.getenv('PG_HOST')\n",
    "# database = os.getenv('PG_DATABASE')\n",
    "# user = os.getenv('PG_USER')\n",
    "# password = os.getenv('PG_PASSWORD')\n",
    "\n",
    "# # Create SQLAlchemy engine\n",
    "# engine = create_engine(f'postgresql://{user}:{password}@{host}/{database}', pool_pre_ping=True)\n",
    "\n",
    "# # Create a session factory\n",
    "# Session = sessionmaker(bind=engine)\n",
    "# session = Session()\n",
    "\n",
    "# # Type conversion of Location_ID column to remove preceding L, if necessary, to store the number as an integer.\n",
    "# pa_observations_df['Location_ID'] = pa_observations_df['Location_ID'].astype(str).apply(lambda x: int(x[1:]) if x.startswith('L') else int(x))\n",
    "\n",
    "# # Create SQLAlchemy table object\n",
    "# metadata = MetaData()\n",
    "# table = Table(\n",
    "#     'Recent_Observations',\n",
    "#     metadata,\n",
    "#     Column('Index', Integer, primary_key=True, autoincrement=True),\n",
    "#     Column('Species_Code', String),\n",
    "#     Column('Common_Name', String),\n",
    "#     Column('Scientific_Name', String),\n",
    "#     Column('Location_ID', Integer),\n",
    "#     Column('Location_Name', String),\n",
    "#     Column('Observation_Date', String),\n",
    "#     Column('Quantity_Observed', Integer),\n",
    "#     Column('Latitude', String),\n",
    "#     Column('Longitude', String),\n",
    "#     Column('Location_Private', Boolean)\n",
    "# )\n",
    "\n",
    "# metadata.create_all(engine)\n",
    "\n",
    "# # Insert the DataFrame into the database table\n",
    "# try:\n",
    "#     with engine.begin() as connection:\n",
    "#         for index, row in pa_observations_df.iterrows():\n",
    "#             print(\"Inserting row: \", row) # for debugging\n",
    "#             insert_stmt = table.insert().values(\n",
    "#                 Species_Code=row['Species_Code'],\n",
    "#                 Common_Name=row['Common_Name'],\n",
    "#                 Scientific_Name=row['Scientific_Name'],\n",
    "#                 Location_ID=row['Location_ID'],\n",
    "#                 Location_Name=row['Location_Name'],\n",
    "#                 Observation_Date=row['Observation_Date'],\n",
    "#                 Quantity_Observed=int(row['Quantity_Observed']),\n",
    "#                 Latitude=float(row['Latitude']),\n",
    "#                 Longitude=float(row['Longitude']),\n",
    "#                 Location_Private=bool(row['Location_Private'])\n",
    "#             )\n",
    "#             connection.execute(insert_stmt)\n",
    "\n",
    "#     print(\"Data insertion successful!\")\n",
    "# except Exception as e:\n",
    "#     print(\"An error occurred during data insertion:\", str(e))\n",
    "\n",
    "# session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_observations_df[(pa_observations_df.Common_Name == 'Pileated Woodpecker')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_observations_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_hotspots_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "total_species_at_hotspots = pa_hotspots_df['Total_Species_Recorded_at_Location'].values\n",
    "\n",
    "plt.hist(total_species_at_hotspots)\n",
    "plt.title('Total Species Recorded at Each Hotspot')\n",
    "plt.xlabel('Hotspot')\n",
    "plt.ylabel('Number of Species Recorded')\n",
    "plt.show()\n",
    "\n",
    "# This histogram makes zero sense analytically, but hey, at least I have a histogram now!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
